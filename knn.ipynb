{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup `matplotlib` formatting options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as plticker\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 25}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('text', usetex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *\n",
    "from wknn import *\n",
    "from search import *\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data generation functions from the distribution described in section 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the data we're generating is about what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100000\n",
    "x, y = generate_data(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 0.005\n",
    "bins = np.arange(0, 1 + interval, interval)\n",
    "hists = [np.histogram(x.squeeze(), bins=bins, weights=(y == i).astype('float64'), density=False)[0] \\\n",
    "         for i in range(3)]\n",
    "centers = (bins[:-1] + bins[1:]) / 2\n",
    "for hist in hists:\n",
    "    plt.scatter(centers, hist, s=2)\n",
    "for eta_val in etas(centers):\n",
    "    plt.plot(centers, eta_val * n / centers.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial(train_X, train_y, wknn, granularity=10000, search='coordinate', **kwargs):\n",
    "    wknn.fit(train_X, train_y)\n",
    "    emp_f1s, wts = zip(*(Searcher.search_dispatch(search)(wknn, train_X, train_y, **kwargs)))\n",
    "    true_f1s = []\n",
    "    for wt in wts:\n",
    "        wknn.set_weights(wt)\n",
    "        true_f1s.append(true_f1_score(wknn, granularity=granularity))\n",
    "    return emp_f1s, true_f1s, wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializle knn\n",
    "init_weights = np.array([0.3, 0.3, 0.4])\n",
    "wknn = WeightedKNN(wknn_weights=init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing effect of different step sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(326)\n",
    "\n",
    "train_n = 1000\n",
    "train_X, train_y = generate_data(train_n)\n",
    "steps = 20\n",
    "step_sizes = [0.01, 0.05]\n",
    "results = []\n",
    "for step_size in step_sizes:\n",
    "    wknn.set_weights(init_weights)\n",
    "    emp_f1s, true_f1s, _ = run_trial(train_X, train_y, wknn, steps=steps, step_size=step_size)\n",
    "    results.extend([{'step size': step_size, 't': idx, 'metric': 'empirical F1', 'Score': val} for idx, val in enumerate(emp_f1s)] + \\\n",
    "                  [{'step size': step_size, 't': idx, 'metric': 'true F1', 'Score': val} for idx, val in enumerate(true_f1s)])\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(results)\n",
    "df['prod'] = df.apply(lambda x: 'step=' + str(x['step size']) + ', ' + x['metric'], axis=1)\n",
    "plt.figure(figsize=(12, 10), facecolor='white')\n",
    "blue, orange = sns.color_palette(n_colors=2)\n",
    "sns.lineplot(data=df, x='t', y='Score', hue='prod', style='prod', palette=[blue, blue, orange, orange], linewidth=4)\n",
    "loc = plticker.MultipleLocator(base=2) # this locator puts ticks at regular intervals\n",
    "plt.gca().xaxis.set_major_locator(loc)\n",
    "plt.gca().set_xlim(0, 20)\n",
    "handles, old_labels = plt.gca().get_legend_handles_labels()\n",
    "labels = [r'$\\alpha=0.01, \\widehat{\\mathrm{F1}}(q_t)$', r'$\\alpha=0.01, \\mathrm{F1}(q_t)$', \\\n",
    "          r'$\\alpha=0.05, \\widehat{\\mathrm{F1}}(q_t)$', r'$\\alpha=0.05, \\mathrm{F1}(q_t)$']\n",
    "for handle in handles:\n",
    "    handle.set_linewidth(4)\n",
    "plt.gca().legend(handles=handles[1:], labels=labels, loc='center right', bbox_to_anchor=(1, 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(322)\n",
    "trials = 50\n",
    "\n",
    "weights_list = weight_gen(3, 100)\n",
    "def task(data):\n",
    "    train_n, (i, (train_X, train_y)), search = data\n",
    "    if search == 'none':\n",
    "        weighting = np.ones(3) / 3\n",
    "        weighting[2] = 1 - weighting[0] - weighting[1]\n",
    "        wknn.set_weights(weighting)\n",
    "        emp_f1, true_f1 = (f1_eval(wknn.predict(train_X), train_y), true_f1_score(wknn))\n",
    "    else:\n",
    "        kwargs = {'steps': steps, 'step_size': 0.01} if search == 'coordinate' else {'weights_list': weights_list}\n",
    "        emp_f1s, true_f1s, weightings = run_trial(train_X, train_y, wknn, granularity=10000, search=search, **kwargs)\n",
    "        emp_f1, true_f1, weighting = emp_f1s[-1], true_f1s[-1], weightings[-1]\n",
    "\n",
    "    index_dict = {'Trial': i, 'n': train_n, 'Algorithm': search} \n",
    "    return[{ **index_dict, 'Metric': 'empirical', 'Score': emp_f1}, \\\n",
    "                      { **index_dict, 'Metric': 'true', 'Score': true_f1},\n",
    "                      { **index_dict, 'Metric': 'true', **{f'Weight_{idx}': wt for idx, wt in enumerate(weighting)}}]\n",
    "        \n",
    "for train_n in tqdm([50] + list(range(100, 2600, 100)), desc='Training n', leave=False):\n",
    "    wknn.set_weights(init_weights)\n",
    "    datas = [generate_data(train_n) for i in range(trials)]\n",
    "    with Pool(trials) as p: \n",
    "        n_results.extend([entry for entries in p.map(task, product([train_n], enumerate(datas), ['coordinate', 'grid', 'none'])) \\\n",
    "                          for entry in entries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df = pd.DataFrame.from_records(n_results)\n",
    "if not os.path.exists('results'):\n",
    "    os.mkdir('results')\n",
    "n_df.to_pickle('results/synthetic_macro.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_df = n_df.groupby(['n', 'Algorithm', 'Metric'], as_index=False).mean()\n",
    "disp_df['algometric'] = disp_df.apply(lambda x: x['Algorithm'] + ', ' + x['Metric'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_legend_labels(ax, labels, linewidth):\n",
    "    handles, _ = ax.get_legend_handles_labels()\n",
    "    for handle in handles:\n",
    "        handle.set_linewidth(linewidth)\n",
    "    ax.legend(handles=handles[1:], labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8), facecolor='white')\n",
    "sns.lineplot(data=disp_df[disp_df['n'] <= 2500][disp_df['Metric'] == 'true'], \\\n",
    "             x='n', y='Score', hue='algometric', style='algometric', \\\n",
    "             legend='brief')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df = disp_df[disp_df['Algorithm'] != 'none'].copy()\n",
    "def abs_diff(x):\n",
    "    diff = np.abs(x.iloc[0]['Score'] - x.iloc[1]['Score'])\n",
    "    n = x.iloc[0]['n']\n",
    "    return pd.DataFrame([[n, diff]], columns=['n', 'Diff'])\n",
    "res_df = diff_df[diff_df['Metric'] == 'true'].groupby(['n'], as_index=False)[['n', 'Score']].apply(abs_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8), facecolor='white')\n",
    "\n",
    "sns.lineplot(data=res_df, \\\n",
    "             x='n', y='Diff', \\\n",
    "             palette=[blue, blue, orange, orange], linewidth=linewidth, dashes=[\"\", (5, 2), (1, 2, 16, 2), (1, 2, 5, 2)], \\\n",
    "             legend='brief')\n",
    "plt.gca().legend(handles=plt.gca().lines[::(len(res_df) + 1)], labels=[\"$|\\mathrm{F1}(q_{\\mathrm{grid}}) - \\mathrm{F1}(q^{(T)})|$\"])\n",
    "\n",
    "plt.ylabel('Difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8), facecolor='white')\n",
    "def nearest_to_mean(x):\n",
    "    median_dist = np.abs(x['Score'] - x['Score'].mean())\n",
    "    mins = x[median_dist == median_dist.min()]\n",
    "    res =  mins.head(1)\n",
    "    return res\n",
    "\n",
    "def l2_wt_dist(x):\n",
    "    weights = x[['Weight_0', 'Weight_1', 'Weight_2']].to_numpy()\n",
    "    l2 = np.linalg.norm(weights[0] - weights[1], 2)\n",
    "    return pd.DataFrame([[x['n'].iloc[0], l2]], columns=['n', 'L2 Distance'])\n",
    "\n",
    "o_df = diff_df[diff_df['Metric'] == 'true'].groupby(['Algorithm', 'n', 'Trial'], as_index=False).max()\n",
    "\n",
    "o_df = o_df.groupby(['Algorithm', 'n'], as_index=False).mean()\n",
    "o_df = o_df.groupby('n', as_index=False)[['n', 'Weight_0', 'Weight_1', 'Weight_2']].apply(l2_wt_dist)\n",
    "\n",
    "plt.figure(figsize=(12, 8), facecolor='white')\n",
    "sns.lineplot(data=o_df, x='n', y='L2 Distance', linewidth=linewidth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
